#include <liblearning/deep/backprop_neuron_layer.h>

using namespace deep;

MatrixMapType backprop_neuron_layer::get_W()
{
	return W;
}


MatrixMapType backprop_neuron_layer::get_diff_W()
{
	return diff_W;
}

VectorMapType backprop_neuron_layer::get_b()
{
	return b;
}

VectorMapType backprop_neuron_layer::get_diff_b()
{
	return diff_b;
}

MatrixType backprop_neuron_layer::get_activation()
{
	if (!record_activation)
	{
		throw runtime_error("the activation is not recorded");
	}
	return activation;
}


MatrixType backprop_neuron_layer::get_output()
{
	if (!record_output)
	{
		throw runtime_error("the output is not recorded");
	}
	return output;
}

backprop_neuron_layer::backprop_neuron_layer(int input_dim, int output_dim, bool record_output_, bool record_activation_)
: W(), b(b_),record_output(record_output_),record_activation(record_activation_)
{

}


 void backprop_neuron_layer::backprop_diff(const MatrixType & input, const MatrixType & delta)
 {

	//dWb_mat = delta*[self.layered_output{2*num_maps}', ones(N,1)];

#if defined USE_PARTIAL_GPU
	GPUMatrixType gDelta = delta, gInput = input, gDiffw;
	GPUVectorType gDiffb;

	gDiffw = gDelta*gInput.transpose();
	gDiffb = gDelta.rowwise().sum();

	diff_W = (MatrixType) gDiffw;
	diff_b = (VectorType) gDiffb;

#else
	diff_W.noalias() = delta*input.transpose();
	diff_b.noalias() = delta.rowwise().sum();
#endif


}
